{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1><span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Processing-Data-Files\" data-toc-modified-id=\"Processing-Data-Files-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Processing Data Files</a></span></li><li><span><a href=\"#Fun-with-Files-and-Directories\" data-toc-modified-id=\"Fun-with-Files-and-Directories-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Fun with Files and Directories</a></span></li><li><span><a href=\"#Parsing-and-Processing-Data\" data-toc-modified-id=\"Parsing-and-Processing-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parsing and Processing Data</a></span></li><li><span><a href=\"#Processing-Infinite-Data\" data-toc-modified-id=\"Processing-Infinite-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Processing Infinite Data</a></span></li><li><span><a href=\"#Feeding-the-Pipeline\" data-toc-modified-id=\"Feeding-the-Pipeline-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Feeding the Pipeline</a></span></li><li><span><a href=\"#Extending-the-pipeline\" data-toc-modified-id=\"Extending-the-pipeline-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extending the pipeline</a></span></li><li><span><a href=\"#Advanced-Data-Routing\" data-toc-modified-id=\"Advanced-Data-Routing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Advanced Data Routing</a></span></li><li><span><a href=\"#Various-Programming-Tricks-(And-Debugging)\" data-toc-modified-id=\"Various-Programming-Tricks-(And-Debugging)-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Various Programming Tricks (And Debugging)</a></span></li><li><span><a href=\"#Parsing-and-Printing\" data-toc-modified-id=\"Parsing-and-Printing-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Parsing and Printing</a></span></li><li><span><a href=\"#Co-routines\" data-toc-modified-id=\"Co-routines-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Co-routines</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20329184\n"
     ]
    }
   ],
   "source": [
    "# nongenlog.py\n",
    "#\n",
    "# Sum up the number of bytes transferred in an Apache log file\n",
    "# using a simple for-loop.   We're not using generators here.\n",
    "\n",
    "wwwlog = open(\"access-log\")\n",
    "total = 0\n",
    "for line in wwwlog:\n",
    "    bytestr = line.rsplit(None, 1)[1]\n",
    "    if bytestr != \"-\":\n",
    "        total += int(bytestr)\n",
    "\n",
    "print(\"Total\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20329184\n"
     ]
    }
   ],
   "source": [
    "# genlog.py\n",
    "#\n",
    "# Sum up the bytes transferred in an Apache server log using\n",
    "# generator expressions\n",
    "\n",
    "wwwlog = open(\"access-log\")\n",
    "bytecolumn = (line.rsplit(None, 1)[1] for line in wwwlog)\n",
    "bytes = (int(x) for x in bytecolumn if x != \"-\")\n",
    "\n",
    "print(\"Total\", sum(bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage : makebig.py repetitions\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orz/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Make a big log file for testing\n",
    "\n",
    "import sys\n",
    "\n",
    "if len(sys.argv) != 2:\n",
    "    print(\"Usage : makebig.py repetitions\", file=sys.stderr)\n",
    "    raise SystemExit(1)\n",
    "\n",
    "data = open(\"access-log\").read()\n",
    "\n",
    "f = open(\"big-access-log\", \"w\")\n",
    "for i in xrange(int(sys.argv[1])):\n",
    "    f.write(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with Files and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbar\u001b[0m/  \u001b[01;34mfoo\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "% ls ./www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;36maccess-log\u001b[0m*  \u001b[01;36maccess-log-0108.bz2\u001b[0m*  \u001b[01;36maccess-log-0208.bz2\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls ./www/bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;36maccess-log\u001b[0m*  \u001b[01;36maccess-log-0108.gz\u001b[0m*  \u001b[01;36maccess-log-0208.gz\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "% ls ./www/foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www/foo/access-log\n",
      "www/foo/access-log-0108.gz\n",
      "www/foo/access-log-0208.gz\n",
      "www/bar/access-log\n",
      "www/bar/access-log-0208.bz2\n",
      "www/bar/access-log-0108.bz2\n"
     ]
    }
   ],
   "source": [
    "# genfind.py\n",
    "#\n",
    "# A function that generates files that match a given filename pattern\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "def gen_find(filepat, top):\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist, filepat):\n",
    "            yield os.path.join(path, name)\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lognames = gen_find(\"access-log*\", \"www\")\n",
    "    for name in lognames:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='www/foo/access-log' mode='r' encoding='UTF-8'>\n",
      "<gzip _io.BufferedReader name='www/foo/access-log-0108.gz' 0x7f0f6c67f588>\n",
      "<gzip _io.BufferedReader name='www/foo/access-log-0208.gz' 0x7f0f6c67f940>\n",
      "<_io.TextIOWrapper name='www/bar/access-log' mode='r' encoding='UTF-8'>\n",
      "<bz2.BZ2File object at 0x7f0f6c67f978>\n",
      "<bz2.BZ2File object at 0x7f0f6c67fc88>\n"
     ]
    }
   ],
   "source": [
    "# genopen.py\n",
    "#\n",
    "# Takes a sequence of filenames as input and yields a sequence of file\n",
    "# objects that have been suitably open\n",
    "\n",
    "import gzip, bz2\n",
    "\n",
    "\n",
    "def gen_open(filenames):\n",
    "    for name in filenames:\n",
    "        if name.endswith(\".gz\"):\n",
    "            yield gzip.open(name)\n",
    "        elif name.endswith(\".bz2\"):\n",
    "            yield bz2.BZ2File(name)\n",
    "        else:\n",
    "            yield open(name)\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from genfind import gen_find\n",
    "\n",
    "    lognames = gen_find(\"access-log*\", \"www\")\n",
    "    logfiles = gen_open(lognames)\n",
    "    for f in logfiles:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /ply/ply.html HTTP/1.1\" 200 97238\n",
      "\n",
      "140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:15:40 -0600] \"GET / HTTP/1.1\" 200 4447\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:15:41 -0600] \"GET /images/Davetubes.jpg HTTP/1.1\" 200 60025\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:15:42 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:15:49 -0600] \"GET /software.html HTTP/1.1\" 200 3163\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:16:10 -0600] \"GET /ply/index.html HTTP/1.1\" 200 8018\n",
      "\n",
      "75.54.118.139 - - [24/Feb/2008:00:16:11 -0600] \"GET /ply/bookplug.gif HTTP/1.1\" 200 23903\n",
      "\n",
      "213.145.165.82 - - [24/Feb/2008:00:16:19 -0600] \"GET /ply/ HTTP/1.1\" 200 8018\n",
      "\n",
      "128.143.38.83 - - [24/Feb/2008:00:31:39 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gencat.py\n",
    "#\n",
    "# Concatenate multiple generators into a single sequence\n",
    "\n",
    "import itertools\n",
    "\n",
    "def gen_cat(sources):\n",
    "    for s in sources:\n",
    "        for item in s:\n",
    "            yield item\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from genfind import gen_find\n",
    "    from genopen import gen_open\n",
    "\n",
    "    lognames = gen_find(\"access-log*\", \"www\")\n",
    "    logfiles = gen_open(lognames)\n",
    "    loglines = gen_cat(logfiles)\n",
    "    for line in itertools.islice(loglines, 10):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.107.0.112 - - [24/Feb/2008:03:02:22 -0600] \"GET /ply/ply-2.2.tar.gz HTTP/1.1\" 200 142210\n",
      "\n",
      "74.6.8.73 - - [24/Feb/2008:03:09:17 -0600] \"GET /ply/ply-1.2.tar.gz HTTP/1.0\" 200 64334\n",
      "\n",
      "74.6.8.73 - - [24/Feb/2008:03:34:07 -0600] \"GET /ply/ply-2.1.tar.gz HTTP/1.0\" 200 107720\n",
      "\n",
      "61.230.94.215 - - [24/Feb/2008:04:45:55 -0600] \"GET /ply/ply-1.0.tar.gz HTTP/1.1\" 200 60130\n",
      "\n",
      "61.230.94.215 - - [24/Feb/2008:04:48:05 -0600] \"GET /ply/ply-2.3.tar.gz HTTP/1.1\" 200 115318\n",
      "\n",
      "150.210.155.167 - - [24/Feb/2008:09:22:11 -0600] \"GET /ply/ply-2.3.tar.gz HTTP/1.1\" 200 115318\n",
      "\n",
      "74.6.8.73 - - [24/Feb/2008:10:34:02 -0600] \"GET /ply/ply-1.3.1.tar.gz HTTP/1.0\" 304 -\n",
      "\n",
      "201.141.81.60 - - [24/Feb/2008:13:33:31 -0600] \"GET /ply/ply-2.3.tar.gz HTTP/1.1\" 200 115318\n",
      "\n",
      "74.6.22.143 - - [24/Feb/2008:14:57:30 -0600] \"GET /ply/ply-1.4.tar.gz HTTP/1.0\" 200 66002\n",
      "\n",
      "189.13.184.120 - - [24/Feb/2008:14:59:40 -0600] \"GET /ply/ply-2.3.tar.gz HTTP/1.1\" 200 115318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gengrep.py\n",
    "#\n",
    "# Grep a sequence of lines that match a re pattern\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "\n",
    "def gen_grep(pat, lines):\n",
    "    patc = re.compile(pat)\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line.decode()\n",
    "        except AttributeError:\n",
    "            if patc.search(line):\n",
    "                yield line\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from genfind import gen_find\n",
    "    from genopen import gen_open\n",
    "    from gencat import gen_cat\n",
    "\n",
    "    lognames = gen_find(\"access-log*\", \"www\")\n",
    "    logfiles = gen_open(lognames)\n",
    "    loglines = gen_cat(logfiles)\n",
    "\n",
    "    # Look for ply downloads (PLY is my own Python package)\n",
    "    plylines = gen_grep(r\"ply-.*\\.gz\", loglines)\n",
    "    for line in itertools.islice(plylines, 10):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 37891196\n"
     ]
    }
   ],
   "source": [
    "# bytesgen.py\n",
    "#\n",
    "# An example of chaining together different generators into a processing\n",
    "# pipeline.\n",
    "\n",
    "from genfind import *\n",
    "from genopen import *\n",
    "from gencat import *\n",
    "from gengrep import *\n",
    "\n",
    "pat = r\"ply-.*\\.gz\"\n",
    "logdir = \"www\"\n",
    "\n",
    "filenames = gen_find(\"access-log*\", logdir)\n",
    "logfiles = gen_open(filenames)\n",
    "loglines = gen_cat(logfiles)\n",
    "patlines = gen_grep(pat, loglines)\n",
    "bytecol = (line.rsplit(None, 1)[1] for line in patlines)\n",
    "bytes = (int(x) for x in bytecol if x != \"-\")\n",
    "\n",
    "print(\"Total\", sum(bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "access log\n",
    "\n",
    "```\n",
    "140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /ply/ply.html HTTP/1.1\" 200 97238\n",
    "140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
    "75.54.118.139 - - [24/Feb/2008:00:15:40 -0600] \"GET / HTTP/1.1\" 200 4447\n",
    "75.54.118.139 - - [24/Feb/2008:00:15:41 -0600] \"GET /images/Davetubes.jpg HTTP/1.1\" 200 60025\n",
    "75.54.118.139 - - [24/Feb/2008:00:15:42 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
    "75.54.118.139 - - [24/Feb/2008:00:15:49 -0600] \"GET /software.html HTTP/1.1\" 200 3163\n",
    "75.54.118.139 - - [24/Feb/2008:00:16:10 -0600] \"GET /ply/index.html HTTP/1.1\" 200 8018\n",
    "75.54.118.139 - - [24/Feb/2008:00:16:11 -0600] \"GET /ply/bookplug.gif HTTP/1.1\" 200 23903\n",
    "213.145.165.82 - - [24/Feb/2008:00:16:19 -0600] \"GET /ply/ HTTP/1.1\" 200 8018\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('71.57.91.136', '-', '-', '28/Feb/2008:12:39:34 -0600', 'GET', '/favicon.ico', 'HTTP/1.1', '404', '133')\n",
      "('71.57.91.136', '-', '-', '28/Feb/2008:12:39:34 -0600', 'GET', '/dynamic/06FilesAndText.pdf', 'HTTP/1.1', '206', '181019')\n",
      "('128.135.24.9', '-', '-', '28/Feb/2008:12:41:14 -0600', 'GET', '/', 'HTTP/1.1', '200', '4447')\n",
      "('128.135.24.9', '-', '-', '28/Feb/2008:12:41:14 -0600', 'GET', '/images/Davetubes.jpg', 'HTTP/1.1', '200', '60025')\n",
      "('128.135.24.9', '-', '-', '28/Feb/2008:12:41:14 -0600', 'GET', '/favicon.ico', 'HTTP/1.1', '404', '133')\n",
      "('128.135.24.9', '-', '-', '28/Feb/2008:12:41:19 -0600', 'GET', '/dynamic/index.html', 'HTTP/1.1', '200', '5313')\n",
      "('128.135.24.9', '-', '-', '28/Feb/2008:12:41:23 -0600', 'GET', '/dynamic/07Functional.pdf', 'HTTP/1.1', '200', '133908')\n",
      "('208.97.218.10', '-', '-', '28/Feb/2008:12:50:17 -0600', 'GET', '/python.html', 'HTTP/1.1', '200', '18870')\n",
      "('208.97.218.10', '-', '-', '28/Feb/2008:12:50:17 -0600', 'GET', '/images/NerdRanchEurope.jpg', 'HTTP/1.1', '200', '99542')\n",
      "('208.97.218.10', '-', '-', '28/Feb/2008:12:50:17 -0600', 'GET', '/favicon.ico', 'HTTP/1.1', '404', '133')\n"
     ]
    }
   ],
   "source": [
    "# retuple.py\n",
    "#\n",
    "# Read a sequence of log lines and parse them into a sequence of tuples\n",
    "\n",
    "loglines = open(\"access-log\")\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "logpats = r\"(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \" r'\"(\\S+) (\\S+) (\\S+)\" (\\S+) (\\S+)'\n",
    "\n",
    "logpat = re.compile(logpats)\n",
    "\n",
    "groups = (logpat.match(line) for line in loglines)\n",
    "tuples = (g.groups() for g in groups if g)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for t in itertools.islice(tuples, 10):\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': '404', 'bytes': '133'}\n",
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/dynamic/06FilesAndText.pdf', 'proto': 'HTTP/1.1', 'status': '206', 'bytes': '181019'}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '4447'}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/images/Davetubes.jpg', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '60025'}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': '404', 'bytes': '133'}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:19 -0600', 'method': 'GET', 'request': '/dynamic/index.html', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '5313'}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:23 -0600', 'method': 'GET', 'request': '/dynamic/07Functional.pdf', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '133908'}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/python.html', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '18870'}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/images/NerdRanchEurope.jpg', 'proto': 'HTTP/1.1', 'status': '200', 'bytes': '99542'}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': '404', 'bytes': '133'}\n"
     ]
    }
   ],
   "source": [
    "# redict.py\n",
    "#\n",
    "# Read a sequence of log lines and parse them into a sequence of dictionaries\n",
    "\n",
    "loglines = open(\"access-log\")\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "logpats = r\"(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \" r'\"(\\S+) (\\S+) (\\S+)\" (\\S+) (\\S+)'\n",
    "\n",
    "logpat = re.compile(logpats)\n",
    "\n",
    "groups = (logpat.match(line) for line in loglines)\n",
    "tuples = (g.groups() for g in groups if g)\n",
    "\n",
    "colnames = (\n",
    "    \"host\",\n",
    "    \"referrer\",\n",
    "    \"user\",\n",
    "    \"datetime\",\n",
    "    \"method\",\n",
    "    \"request\",\n",
    "    \"proto\",\n",
    "    \"status\",\n",
    "    \"bytes\",\n",
    ")\n",
    "\n",
    "log = (dict(list(zip(colnames, t))) for t in tuples)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for x in  itertools.islice(log, 10):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n",
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/dynamic/06FilesAndText.pdf', 'proto': 'HTTP/1.1', 'status': 206, 'bytes': 181019}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 4447}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/images/Davetubes.jpg', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 60025}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:19 -0600', 'method': 'GET', 'request': '/dynamic/index.html', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 5313}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:23 -0600', 'method': 'GET', 'request': '/dynamic/07Functional.pdf', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 133908}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/python.html', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 18870}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/images/NerdRanchEurope.jpg', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 99542}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n"
     ]
    }
   ],
   "source": [
    "# fieldmap.py\n",
    "#\n",
    "# Take a sequence of dictionaries and remap one of the fields\n",
    "\n",
    "\n",
    "def field_map(dictseq, name, func):\n",
    "    for d in dictseq:\n",
    "        d[name] = func(d[name])\n",
    "        yield d\n",
    "\n",
    "\n",
    "# Example\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    loglines = open(\"access-log\")\n",
    "\n",
    "    import re\n",
    "    import itertools\n",
    "    \n",
    "    logpats = r\"(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \" r'\"(\\S+) (\\S+) (\\S+)\" (\\S+) (\\S+)'\n",
    "\n",
    "    logpat = re.compile(logpats)\n",
    "\n",
    "    groups = (logpat.match(line) for line in loglines)\n",
    "    tuples = (g.groups() for g in groups if g)\n",
    "\n",
    "    colnames = (\n",
    "        \"host\",\n",
    "        \"referrer\",\n",
    "        \"user\",\n",
    "        \"datetime\",\n",
    "        \"method\",\n",
    "        \"request\",\n",
    "        \"proto\",\n",
    "        \"status\",\n",
    "        \"bytes\",\n",
    "    )\n",
    "\n",
    "    log = (dict(list(zip(colnames, t))) for t in tuples)\n",
    "\n",
    "    log = field_map(log, \"status\", int)\n",
    "    log = field_map(log, \"bytes\", lambda s: int(s) if s != \"-\" else 0)\n",
    "\n",
    "    for x in  itertools.islice(log, 10):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /ply/ply.html HTTP/1.1\" 200 97238\n",
      " 140.180.132.213 - - [24/Feb/2008:00:08:59 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      " 75.54.118.139 - - [24/Feb/2008:00:15:40 -0600] \"GET / HTTP/1.1\" 200 4447\n",
      " 75.54.118.139 - - [24/Feb/2008:00:15:41 -0600] \"GET /images/Davetubes.jpg HTTP/1.1\" 200 60025\n",
      " 75.54.118.139 - - [24/Feb/2008:00:15:42 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      " 75.54.118.139 - - [24/Feb/2008:00:15:49 -0600] \"GET /software.html HTTP/1.1\" 200 3163\n",
      " 75.54.118.139 - - [24/Feb/2008:00:16:10 -0600] \"GET /ply/index.html HTTP/1.1\" 200 8018\n",
      " 75.54.118.139 - - [24/Feb/2008:00:16:11 -0600] \"GET /ply/bookplug.gif HTTP/1.1\" 200 23903\n",
      " 213.145.165.82 - - [24/Feb/2008:00:16:19 -0600] \"GET /ply/ HTTP/1.1\" 200 8018\n",
      " 128.143.38.83 - - [24/Feb/2008:00:31:39 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      " "
     ]
    }
   ],
   "source": [
    "# linesdir.py\n",
    "#\n",
    "# Generate a sequence of lines from files in a directory\n",
    "\n",
    "from genfind import *\n",
    "from gencat import *\n",
    "from genopen import *\n",
    "import itertools\n",
    "\n",
    "def lines_from_dir(filepat, dirname):\n",
    "    names = gen_find(filepat, dirname)\n",
    "    files = gen_open(names)\n",
    "    lines = gen_cat(files)\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loglines = lines_from_dir(\"access-log*\", \"www\")\n",
    "    for line in  itertools.islice(loglines, 10):\n",
    "        print(line, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.143.38.83 - - [24/Feb/2008:00:31:51 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "86.132.71.214 - - [24/Feb/2008:00:37:55 -0600] \"GET /python.html HTTP/1.1\" 200 18870\n",
      "\n",
      "86.132.71.214 - - [24/Feb/2008:00:37:55 -0600] \"GET /images/NerdRanchEurope.jpg HTTP/1.1\" 200 99542\n",
      "\n",
      "86.132.71.214 - - [24/Feb/2008:00:37:56 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "86.132.71.214 - - [24/Feb/2008:00:37:56 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "86.132.71.214 - - [24/Feb/2008:00:38:35 -0600] \"GET /favicon.ico HTTP/1.1\" 404 133\n",
      "\n",
      "74.6.25.144 - - [24/Feb/2008:00:48:16 -0600] \"GET /dynamic/01Introduction.pdf HTTP/1.0\" 200 3110734\n",
      "\n",
      "74.6.7.122 - - [24/Feb/2008:00:56:36 -0600] \"GET /python/tutorial/beazley_intro_python/Slides/SLIDE113.HTM HTTP/1.0\" 200 1095\n",
      "\n",
      "125.25.238.64 - - [24/Feb/2008:01:04:47 -0600] \"GET /ply/ HTTP/1.1\" 200 8018\n",
      "\n",
      "125.25.238.64 - - [24/Feb/2008:01:04:49 -0600] \"GET /ply/bookplug.gif HTTP/1.1\" 200 12382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apachelog.py\n",
    "#\n",
    "# Parse an apache log file into a sequence of dictionaries\n",
    "\n",
    "from fieldmap import *\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "logpats = r\"(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \" r'\"(\\S+) (\\S+) (\\S+)\" (\\S+) (\\S+)'\n",
    "\n",
    "logpat = re.compile(logpats)\n",
    "\n",
    "\n",
    "def skip_byte_line(lines):\n",
    "    for line in lines:\n",
    "        try:\n",
    "            line.decode()\n",
    "        except AttributeError:\n",
    "            yield line\n",
    "\n",
    "def apache_log(lines):\n",
    "    lines =  skip_byte_line(lines)\n",
    "    groups = (logpat.match(line) for line in lines)\n",
    "    tuples = (g.groups() for g in groups if g)\n",
    "\n",
    "    colnames = (\n",
    "        \"host\",\n",
    "        \"referrer\",\n",
    "        \"user\",\n",
    "        \"datetime\",\n",
    "        \"method\",\n",
    "        \"request\",\n",
    "        \"proto\",\n",
    "        \"status\",\n",
    "        \"bytes\",\n",
    "    )\n",
    "\n",
    "    log = (dict(list(zip(colnames, t))) for t in tuples)\n",
    "    log = field_map(log, \"status\", int)\n",
    "    log = field_map(log, \"bytes\", lambda s: int(s) if s != \"-\" else 0)\n",
    "\n",
    "    return log\n",
    "\n",
    "\n",
    "# Example use:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from linesdir import *\n",
    "\n",
    "    lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "    log = apache_log(lines)\n",
    "    for r in itertools.islice(loglines, 10):\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/02WorkingWithData.pdf\n",
      "/06FilesAndText.pdf\n",
      "/07Functional.pdf\n",
      "/Doc/index.html\n",
      "/PLYTalk.pdf\n",
      "/Perl98/swigperl.htm\n",
      "/Py96/python96.html\n",
      "/Py97/beazley.html\n",
      "/Python2001/python.html\n",
      "/README\n"
     ]
    }
   ],
   "source": [
    "# query404.py\n",
    "#\n",
    "# Find the set of all documents that 404 in a log file\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "\n",
    "import itertools\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "stat404 = set(r[\"request\"] for r in log if r[\"status\"] == 404)\n",
    "\n",
    "for r in  itertools.islice(sorted(stat404), 10):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/dynamic/01Introduction.pdf', 3110734)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/01Introduction.pdf', 3108482)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/02WorkingWithData.pdf', 3246437)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/ffcache.zip', 4919642)\n",
      "('/dynamic/02WorkingWithData.pdf', 2935451)\n"
     ]
    }
   ],
   "source": [
    "# largefiles.py\n",
    "#\n",
    "# Find all transfers over a megabyte\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "import itertools\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "large = (r for r in log if r[\"bytes\"] > 1000000)\n",
    "\n",
    "for r in  itertools.islice(large, 10):\n",
    "    print((r[\"request\"], r[\"bytes\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4919642 /dynamic/ffcache.zip\n"
     ]
    }
   ],
   "source": [
    "# largest.py\n",
    "#\n",
    "# Find the largest file\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "print(\"%d %s\" % max((r[\"bytes\"], r[\"request\"]) for r in log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.255.238.189\n",
      "203.73.43.189\n",
      "198.54.202.210\n",
      "203.166.87.218\n",
      "62.153.70.82\n",
      "80.229.38.64\n",
      "84.110.221.201\n",
      "210.245.52.8\n",
      "83.204.240.53\n",
      "74.6.26.198\n"
     ]
    }
   ],
   "source": [
    "# hosts.py\n",
    "#\n",
    "# Find unique host IP addresses\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "import itertools\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "hosts = set(r[\"host\"] for r in log)\n",
    "for h in  itertools.islice(hosts, 10):\n",
    "    print(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 690\n"
     ]
    }
   ],
   "source": [
    "# downloads.py\n",
    "#\n",
    "# Find out how many downloads of a specific request\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "request = \"ply/ply-2.3.tar.gz\"\n",
    "\n",
    "total = sum(1 for r in log if r[\"request\"] == \"/ply/ply-2.3.tar.gz\")\n",
    "\n",
    "print(\"Total\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msnbot-65-55-212-77.search.msn.com\n",
      "9.80-202-87.nextgentel.com\n",
      "www.whois.sc\n",
      "72.36.114.239\n",
      "222.122.236.43\n",
      "64.124.85.71.broadcast.zip.zayo.com\n",
      "64.124.85.75.broadcast.zip.zayo.com\n",
      "crawl-b04-s3.orangebot.orange.fr\n",
      "static-88.131.106.15.addr.tdc.se\n",
      "65.55.232.15\n"
     ]
    }
   ],
   "source": [
    "# robots.py\n",
    "#\n",
    "# Find out who has been hitting robots.txt\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "import itertools\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "log = apache_log(lines)\n",
    "\n",
    "addrs = set(r[\"host\"] for r in log if \"robots.txt\" in r[\"request\"])\n",
    "\n",
    "import socket\n",
    "\n",
    "for addr in  itertools.islice(addrs, 10):\n",
    "    try:\n",
    "        print(socket.gethostbyaddr(addr)[0])\n",
    "    except socket.herror:\n",
    "        print(addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# なんかうまく動かない\n",
    "# robotsfast.py\n",
    "#\n",
    "# Find out who has been hitting robots.txt\n",
    "\n",
    "from linesdir import *\n",
    "from apachelog import *\n",
    "\n",
    "lines = lines_from_dir(\"access-log*\", \"www\")\n",
    "lines = (line for line in lines if \"robots.txt\" in line)\n",
    "log = apache_log(lines)\n",
    "\n",
    "addrs = set(r[\"host\"] for r in log if \"robots.txt\" in r[\"request\"])\n",
    "\n",
    "import socket\n",
    "\n",
    "for addr in addrs:\n",
    "    try:\n",
    "        print(socket.gethostbyaddr(addr)[0])\n",
    "    except socket.herror:\n",
    "        print(addr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Infinite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow.py\n",
    "#\n",
    "# Follow a file like tail -f.\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def follow(thefile):\n",
    "    thefile.seek(0, 2)\n",
    "    while True:\n",
    "        line = thefile.readline()\n",
    "        if not line:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "        yield line\n",
    "\n",
    "\n",
    "# Example use\n",
    "# Note : This example requires the use of an apache log simulator.\n",
    "#\n",
    "# Go to the directory run/foo and run the program 'logsim.py' from\n",
    "# that directory.   Run this program as a background process and\n",
    "# leave it running in a separate window.  We'll write program\n",
    "# that read the output file being generated\n",
    "#\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logfile = open(\"run/foo/access-log\", \"r\")\n",
    "    loglines = follow(logfile)\n",
    "    for line in loglines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime404.py\n",
    "#\n",
    "# Print all 404 requests as they happen in the log\n",
    "\n",
    "from apachelog import *\n",
    "from follow import *\n",
    "\n",
    "logfile  = open(\"run/foo/access-log\")\n",
    "loglines = follow(logfile)\n",
    "log      = apache_log(loglines)\n",
    "\n",
    "r404 = (r for r in log if r['status'] == 404)\n",
    "\n",
    "for r in r404:\n",
    "    print(r['host'], r['datetime'], r['request'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genreceive.py\n",
    "#\n",
    "# A generator that yields connections to a TCP socket\n",
    "\n",
    "import socket\n",
    "\n",
    "\n",
    "def receive_connections(addr):\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    s.bind(addr)\n",
    "    s.listen(5)\n",
    "    while True:\n",
    "        client = s.accept()\n",
    "        yield client\n",
    "\n",
    "\n",
    "# Example use\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for c, a in receive_connections((\"\", 9000)):\n",
    "        print(\"Got connection from\", a)\n",
    "        c.send(\"Hello World\\n\")\n",
    "        c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genmessages.py\n",
    "#\n",
    "# A generator that yields messages on a UDP socket\n",
    "\n",
    "import socket\n",
    "\n",
    "\n",
    "def receive_messages(addr, maxsize):\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    s.bind(addr)\n",
    "    while True:\n",
    "        msg = s.recvfrom(maxsize)\n",
    "        yield msg\n",
    "\n",
    "\n",
    "# Example use\n",
    "# To send a message to this generator, use the code \"msgtest.py\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for msg, addr in receive_messages((\"\", 10000), 1024):\n",
    "        print((msg, \"from\", addr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genpickle.py\n",
    "#\n",
    "# Turn a sequence of objects into a sequence of pickle strings\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def gen_pickle(source):\n",
    "    for item in source:\n",
    "        yield pickle.dumps(item)\n",
    "\n",
    "\n",
    "def gen_unpickle(infile):\n",
    "    while True:\n",
    "        try:\n",
    "            item = pickle.load(infile)\n",
    "            yield item\n",
    "       except EOFError:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recivefrom.py\n",
    "#\n",
    "# Receive objects from a different machine\n",
    "\n",
    "import socket\n",
    "from genpickle import *\n",
    "\n",
    "\n",
    "def receivefrom(addr):\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    s.bind(addr)\n",
    "    s.listen(5)\n",
    "    c, a = s.accept()\n",
    "    for item in gen_unpickle(c.makefile()):\n",
    "        yield item\n",
    "    c.close()\n",
    "\n",
    "\n",
    "# Example use:\n",
    "if __name__ == \"__main__\":\n",
    "    for r in receivefrom((\"127.0.0.1\", 15000)):\n",
    "        print(r[\"host\"], r[\"request\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sendto.py\n",
    "#\n",
    "# Send items to a remote machine\n",
    "\n",
    "import socket\n",
    "from genpickle import *\n",
    "\n",
    "\n",
    "def sendto(source, addr):\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.connect(addr)\n",
    "    for pitem in gen_pickle(source):\n",
    "        s.sendall(pitem)\n",
    "    s.close()\n",
    "\n",
    "\n",
    "# Example use.   This requires you to run receivefrom.py\n",
    "# in a different process/window\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from apachelog import *\n",
    "    from follow import *\n",
    "\n",
    "    lines = follow(open(\"run/foo/access-log\"))\n",
    "    log = apache_log(lines)\n",
    "    sendto(log, (\"127.0.0.1\", 15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genqueue.py\n",
    "#\n",
    "# Generate a sequence of items that put onto a queue\n",
    "\n",
    "\n",
    "def sendto_queue(source, thequeue):\n",
    "    for item in source:\n",
    "        thequeue.put(item)\n",
    "    thequeue.put(StopIteration)\n",
    "\n",
    "\n",
    "def genfrom_queue(thequeue):\n",
    "    while True:\n",
    "        item = thequeue.get()\n",
    "        if item is StopIteration:\n",
    "            break\n",
    "        yield item\n",
    "\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # A consumer.   Prints out 404 records.\n",
    "    def print_r404(log_q):\n",
    "        log = genfrom_queue(log_q)\n",
    "        r404 = (r for r in log if r[\"status\"] == 404)\n",
    "        for r in r404:\n",
    "            print(r[\"host\"], r[\"datetime\"], r[\"request\"])\n",
    "\n",
    "    import queue, threading\n",
    "    from follow import *\n",
    "    from apachelog import *\n",
    "\n",
    "    log_q = queue.Queue()\n",
    "    log_thr = threading.Thread(target=print_r404, args=(log_q,))\n",
    "    log_thr.setDaemon(True)\n",
    "    log_thr.start()\n",
    "\n",
    "    # Feed the consumer thread\n",
    "    lines = follow(open(\"run/foo/access-log\"))\n",
    "    log = apache_log(lines)\n",
    "    sendto_queue(log, log_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Routing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genmultiplex.py\n",
    "\n",
    "import threading, queue\n",
    "from genqueue import *\n",
    "from gencat import *\n",
    "\n",
    "\n",
    "def multiplex(sources):\n",
    "    in_q = queue.Queue()\n",
    "    consumers = []\n",
    "    for s in sources:\n",
    "        thr = threading.Thread(target=sendto_queue, args=(s, in_q))\n",
    "        thr.start()\n",
    "        consumers.append(genfrom_queue(in_q))\n",
    "    return gen_cat(consumers)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import follow\n",
    "\n",
    "    foo_log = follow.follow(open(\"run/foo/access-log\"))\n",
    "    bar_log = follow.follow(open(\"run/bar/access-log\"))\n",
    "    for line in multiplex([foo_log, bar_log]):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast.py\n",
    "#\n",
    "# Broadcast a generator source to a collection of consumers\n",
    "\n",
    "\n",
    "def broadcast(source, consumers):\n",
    "    for item in source:\n",
    "        for c in consumers:\n",
    "            c.send(item)\n",
    "\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    class Consumer(object):\n",
    "        def send(self, item):\n",
    "            print(self, \"got\", item)\n",
    "\n",
    "    c1 = Consumer()\n",
    "    c2 = Consumer()\n",
    "    c3 = Consumer()\n",
    "\n",
    "    from follow import *\n",
    "\n",
    "    lines = follow(open(\"run/foo/access-log\"))\n",
    "    broadcast(lines, [c1, c2, c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netsend.py\n",
    "#\n",
    "# Consume items and send them to a remote machine\n",
    "\n",
    "import socket, pickle\n",
    "\n",
    "\n",
    "class NetConsumer(object):\n",
    "    def __init__(self, addr):\n",
    "        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.s.connect(addr)\n",
    "\n",
    "    def send(self, item):\n",
    "        pitem = pickle.dumps(item)\n",
    "        self.s.sendall(pitem)\n",
    "\n",
    "    def close(self):\n",
    "        self.s.close()\n",
    "\n",
    "\n",
    "# Example use.  This requires you to run receivefrom.py first.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from broadcast import *\n",
    "    from follow import *\n",
    "    from apachelog import *\n",
    "\n",
    "    # A class that sends 404 requests to another host\n",
    "    class Stat404(NetConsumer):\n",
    "        def send(self, item):\n",
    "            if item[\"status\"] == 404:\n",
    "                NetConsumer.send(self, item)\n",
    "\n",
    "    stat404 = Stat404((\"\", 15000))\n",
    "\n",
    "    lines = follow(open(\"run/foo/access-log\"))\n",
    "    log = apache_log(lines)\n",
    "    broadcast(log, [stat404])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consthread.py\n",
    "\n",
    "import queue, threading\n",
    "from genqueue import genfrom_queue\n",
    "\n",
    "\n",
    "class ConsumerThread(threading.Thread):\n",
    "    def __init__(self, target):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.setDaemon(True)\n",
    "        self.in_q = queue.Queue()\n",
    "        self.target = target\n",
    "\n",
    "    def send(self, item):\n",
    "        self.in_q.put(item)\n",
    "\n",
    "    def run(self):\n",
    "        self.target(genfrom_queue(self.in_q))\n",
    "\n",
    "\n",
    "# Example use\n",
    "if __name__ == \"__main__\":\n",
    "    from follow import *\n",
    "    from apachelog import *\n",
    "    from broadcast import *\n",
    "\n",
    "    def find_404(log):\n",
    "        for r in (r for r in log if r[\"status\"] == 404):\n",
    "            print(r[\"status\"], r[\"datetime\"], r[\"request\"])\n",
    "\n",
    "    def bytes_transferred(log):\n",
    "        total = 0\n",
    "        for r in log:\n",
    "            total += r[\"bytes\"]\n",
    "            print(\"Total bytes\", total)\n",
    "\n",
    "    c1 = ConsumerThread(find_404)\n",
    "    c1.start()\n",
    "    c2 = ConsumerThread(bytes_transferred)\n",
    "    c2.start()\n",
    "\n",
    "    lines = follow(open(\"run/foo/access-log\"))  # Follow a log\n",
    "    log = apache_log(lines)  # Turn into records\n",
    "    broadcast(log, [c1, c2])  # Broadcast to consumers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Programming Tricks (And Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n",
      "{'host': '71.57.91.136', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:39:34 -0600', 'method': 'GET', 'request': '/dynamic/06FilesAndText.pdf', 'proto': 'HTTP/1.1', 'status': 206, 'bytes': 181019}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 4447}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/images/Davetubes.jpg', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 60025}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:14 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:19 -0600', 'method': 'GET', 'request': '/dynamic/index.html', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 5313}\n",
      "{'host': '128.135.24.9', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:41:23 -0600', 'method': 'GET', 'request': '/dynamic/07Functional.pdf', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 133908}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/python.html', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 18870}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/images/NerdRanchEurope.jpg', 'proto': 'HTTP/1.1', 'status': 200, 'bytes': 99542}\n",
      "{'host': '208.97.218.10', 'referrer': '-', 'user': '-', 'datetime': '28/Feb/2008:12:50:17 -0600', 'method': 'GET', 'request': '/favicon.ico', 'proto': 'HTTP/1.1', 'status': 404, 'bytes': 133}\n"
     ]
    }
   ],
   "source": [
    "# gentrace.py\n",
    "#\n",
    "# Trace a generator by printing items received\n",
    "import itertools\n",
    "\n",
    "\n",
    "def trace(source):\n",
    "    for item in source:\n",
    "        print(item)\n",
    "        yield item\n",
    "\n",
    "\n",
    "# Example use\n",
    "if __name__ == \"__main__\":\n",
    "    from apachelog import *\n",
    "\n",
    "    lines = open(\"access-log\")\n",
    "    log = trace(apache_log(lines))\n",
    "    r404 = itertools.islice((r for r in log if r[\"status\"] == 404), 3)\n",
    "\n",
    "    for r in r404:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storelast.py\n",
    "#\n",
    "# An iterator that stores the last value returned.  \n",
    "\n",
    "class storelast(object):\n",
    "    def __init__(self,source):\n",
    "        self.source = source\n",
    "    def __next__(self):\n",
    "        item = next(self.source)\n",
    "        self.last = item\n",
    "        return item\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "# Example\n",
    "if __name__ == '__main__':\n",
    "    from follow import *\n",
    "    from apachelog import *\n",
    "\n",
    "    lines = storelast(follow(open(\"run/foo/access-log\")))\n",
    "    log   = apache_log(lines)\n",
    "\n",
    "    for r in log:\n",
    "        print(r)\n",
    "        print(lines.last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genshutdown.py\n",
    "#\n",
    "# Example of shutting down a generator\n",
    "#\n",
    "# Requires you to run run/foo/logsim.py to get a real-time source\n",
    "\n",
    "from follow import *\n",
    "\n",
    "lines = follow(open(\"run/foo/access-log\"))\n",
    "for i, line in enumerate(lines):\n",
    "    print(line, end=\" \")\n",
    "    if i == 10:\n",
    "        lines.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AA\u0000\u0000\u0000\u0000\u0000\u0000        100      32.20\n",
      "  IBM\u0000\u0000\u0000\u0000\u0000         50      91.10\n",
      "  CAT\u0000\u0000\u0000\u0000\u0000        150      83.44\n",
      "  MSFT\u0000\u0000\u0000\u0000        200      51.23\n",
      "  GE\u0000\u0000\u0000\u0000\u0000\u0000         95      40.37\n",
      "  MSFT\u0000\u0000\u0000\u0000         50      65.10\n",
      "  IBM\u0000\u0000\u0000\u0000\u0000        100      70.44\n",
      "==== no more records ===\n"
     ]
    }
   ],
   "source": [
    "# genrecord.py\n",
    "import struct\n",
    "\n",
    "\n",
    "def gen_records(record_format, thefile):\n",
    "    record_size = struct.calcsize(record_format)\n",
    "    while True:\n",
    "        raw_record = thefile.read(record_size)\n",
    "        if not raw_record:\n",
    "            print('==== no more records ===')\n",
    "            break\n",
    "        yield struct.unpack(record_format, raw_record)\n",
    "\n",
    "\n",
    "# Example use\n",
    "if __name__ == \"__main__\":\n",
    "    f = open(\"stockdata.bin\", \"rb\")\n",
    "    for name, shares, price in gen_records(\"<8sif\", f):\n",
    "        print(\"%10s %10d %10.2f\" % (name.decode(), shares, price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "\n",
      "Look at me count to 10\n",
      "   0\n",
      "   1\n",
      "   2\n",
      "   3\n",
      "   4\n",
      "   5\n",
      "   6\n",
      "   7\n",
      "   8\n",
      "   9\n",
      "I'm done!\n",
      "\n",
      "\n",
      "inside of count.txt\n"
     ]
    }
   ],
   "source": [
    "# print_count.py\n",
    "\n",
    "\n",
    "def print_count(n):\n",
    "    yield \"Hello World\\n\"\n",
    "    yield \"\\n\"\n",
    "    yield \"Look at me count to %d\\n\" % n\n",
    "    for i in range(n):\n",
    "        yield \"   %d\\n\" % i\n",
    "    yield \"I'm done!\\n\"\n",
    "\n",
    "\n",
    "# Example:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = print_count(10)\n",
    "    print(\"\".join(out))\n",
    "\n",
    "    # Route to a file\n",
    "    out = print_count(5)\n",
    "    f = open(\"count.txt\", \"wb\")\n",
    "    print(\"\")\n",
    "    for chunk in out:\n",
    "        f.write(chunk.encode('utf-8'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\r\n",
      "\r\n",
      "Look at me count to 5\r\n",
      "   0\r\n",
      "   1\r\n",
      "   2\r\n",
      "   3\r\n",
      "   4\r\n",
      "I'm done!\r\n"
     ]
    }
   ],
   "source": [
    "%cat count.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n",
      "Kaboom!\n"
     ]
    }
   ],
   "source": [
    "# recvcount.py\n",
    "#\n",
    "# Example of a co-routine\n",
    "\n",
    "\n",
    "def recv_count():\n",
    "    try:\n",
    "        while True:\n",
    "            n = (yield) # <= co-routine\n",
    "            print(\"T-minus\", n)\n",
    "    except GeneratorExit:\n",
    "        print(\"Kaboom!\")\n",
    "\n",
    "\n",
    "r = recv_count()\n",
    "next(r)\n",
    "for i in range(5, 0, -1):\n",
    "    r.send(i)\n",
    "\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n",
      "Kaboom!\n"
     ]
    }
   ],
   "source": [
    "# consumer.py\n",
    "#\n",
    "# consumer decorator and co-routine example\n",
    "\n",
    "\n",
    "def consumer(func):\n",
    "    def start(*args, **kwargs):\n",
    "        c = func(*args, **kwargs)\n",
    "        next(c)\n",
    "        return c\n",
    "\n",
    "    return start\n",
    "\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    @consumer # <= 上と違って、next() しなくて良くなる\n",
    "    def recv_count():\n",
    "        try:\n",
    "            while True:\n",
    "                n = (yield)\n",
    "                print(\"T-minus\", n)\n",
    "        except GeneratorExit:\n",
    "            print(\"Kaboom!\")\n",
    "\n",
    "    r = recv_count()\n",
    "    for i in range(5, 0, -1):\n",
    "        r.send(i)\n",
    "\n",
    "    r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logcoroutine.py\n",
    "#\n",
    "# An example of using co-routines to define consumers for the Apache log data\n",
    "\n",
    "from consumer import *\n",
    "from apachelog import *\n",
    "from follow import *\n",
    "from broadcast import *\n",
    "\n",
    "@consumer\n",
    "def find_404():\n",
    "    while True:\n",
    "        r = (yield)\n",
    "        if r['status'] == 404:\n",
    "            print(r['status'],r['datetime'],r['request'])\n",
    "\n",
    "@consumer\n",
    "def bytes_transferred():\n",
    "    total = 0\n",
    "    while True:\n",
    "        r = (yield)\n",
    "        total += r['bytes']\n",
    "        print(\"Total bytes\", total)\n",
    "\n",
    "lines = follow(open(\"run/foo/access-log\"))\n",
    "log   = apache_log(lines)\n",
    "\n",
    "broadcast(log, [find_404(),bytes_transferred()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
